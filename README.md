# Gradient Boosting from Scratch using NumPy

## Overview
This project implements the Gradient Boosting algorithm from scratch using only NumPy.
No machine learning libraries such as scikit-learn or XGBoost are used.

## Objective
To understand residual learning, loss minimization, and ensemble methods by manually
implementing Gradient Boosting.

## Tools Used
- Python
- NumPy
- Google Colab

## How to Run
1. Install dependencies:
   pip install -r requirements.txt
2. Open the notebook and run all cells.

## Author
Mohamed Jamaludeen
